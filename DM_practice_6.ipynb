{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1i8adKFQS7E-"
   },
   "source": [
    "# **Лабораторна робота 6: Пошук аномалій та вирішення задачі *anomaly detection* за допомогою бібліотек `scikit-learn`та `PyTorch`**\n",
    "**Всі завдання виконуються індивідуально. Використання запозиченого коду буде оцінюватись в 0 балів.**\n",
    "\n",
    "**Лабораторні роботи де в коді буде використаня КИРИЛИЦІ будуть оцінюватись в 20 балів.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvneQUbQRRqZ"
   },
   "source": [
    "### Мета роботи:\n",
    "Ознайомитися з основними методами виявлення аномалій, навчитися використовувати бібліотеки `scikit-learn` та `PyTorch` для реалізації алгоритмів пошуку аномалій, проаналізувати ефективність різних методів на реальних наборах даних з Kaggle.\n",
    "\n",
    "\n",
    "### Опис завдання:\n",
    "\n",
    "1. **Постановка задачі**:\n",
    "   Використовуючи один із доступних наборів даних Kaggle (наприклад, *Credit Card Fraud Detection*, *Network Intrusion*, або інші), вам потрібно розв'язати задачу виявлення аномалій. Основна мета — ідентифікувати аномальні записи серед нормальних. Вибраний набір даних повинен містити мітки аномалій для перевірки результатів.\n",
    "\n",
    "2. **Етапи виконання завдання**:\n",
    "   - Завантажте та підготуйте набір даних.\n",
    "   - Проведіть попередню обробку даних (масштабування, заповнення пропущених значень, видалення нерелевантних ознак).\n",
    "   - Використайте різні методи виявлення аномалій:\n",
    "     - **Методи з бібліотеки scikit-learn**:\n",
    "       - Isolation Forest\n",
    "       - One-Class SVM\n",
    "       - Local Outlier Factor (LOF)\n",
    "     - **Методи з використанням PyTorch**:\n",
    "       - Автоенкодери для виявлення аномалій.\n",
    "   - Порівняйте отримані результати, обчисліть метрики якості (Precision, Recall, F1-Score).\n",
    "   - Оцініть, який метод найкраще підходить для вирішення задачі на вашому наборі даних.\n",
    "\n",
    "### Покрокова інструкція\n",
    "\n",
    "1. **Підготовка середовища**:\n",
    "   - Встановіть необхідні бібліотеки:\n",
    "     ```\n",
    "     pip install scikit-learn torch pandas numpy matplotlib\n",
    "     ```\n",
    "\n",
    "2. **Вибір набору даних з Kaggle**:\n",
    "   Зареєструйтесь на Kaggle та оберіть один із наборів даних для виявлення аномалій. Наприклад:\n",
    "   - [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)\n",
    "   - [Network Intrusion Detection](https://www.kaggle.com/xyuanh/benchmarking-datasets)\n",
    "\n",
    "3. **Попередня обробка даних**:\n",
    "   - Завантажте дані та проведіть їхню початкову обробку.\n",
    "   - Масштабуйте ознаки за допомогою `StandardScaler` або `MinMaxScaler`.\n",
    "   - Розділіть дані на навчальну і тестову вибірки.\n",
    "\n",
    "4. **Методи з бібліотеки `scikit-learn`**:\n",
    "\n",
    "   - **Isolation Forest**:\n",
    "     ```\n",
    "     from sklearn.ensemble import IsolationForest\n",
    "     ```\n",
    "\n",
    "   - **One-Class SVM**:\n",
    "     ```\n",
    "     from sklearn.svm import OneClassSVM\n",
    "     ```\n",
    "\n",
    "   - **Local Outlier Factor**:\n",
    "     ```\n",
    "     from sklearn.neighbors import LocalOutlierFactor\n",
    "     ```\n",
    "\n",
    "5. **Методи на основі нейронних мереж (PyTorch)**:\n",
    "\n",
    "   Використайте автоенкодер для пошуку аномалій. Побудуйте нейронну мережу з енкодером і декодером. Під час навчання порівняйте відновлені дані з вхідними та обчисліть помилку. Записи з великою помилкою можуть бути аномаліями.\n",
    "\n",
    "   - **Реалізація автоенкодера**:\n",
    "     ```\n",
    "     import torch\n",
    "     import torch.nn as nn\n",
    "     import torch.optim as optim\n",
    "     ```\n",
    "\n",
    "6. **Оцінка результатів**:\n",
    "   Використовуйте метрики оцінки якості:\n",
    "   - `Precision`, `Recall`, `F1-score`\n",
    "   ```\n",
    "   from sklearn.metrics import classification_report\n",
    "   ```\n",
    "\n",
    "7. **Звіт**:\n",
    "   - Поясніть, який метод дав найкращі результати.\n",
    "   - Проаналізуйте, чому деякі методи працюють краще на вашому наборі даних.\n",
    "   - Оцініть можливості використання глибоких нейронних мереж (автоенкодерів) для вирішення задачі.\n",
    "\n",
    "\n",
    "### Результати, які необхідно надати:\n",
    "1. Код рішення у вигляді Jupyter Notebook з аналізом результатів та поясненнями.\n",
    "\n",
    "\n",
    "### Дедлайн:\n",
    "[23 жовтня 23:59]\n",
    "\n",
    "\n",
    "### Корисні ресурси:\n",
    "- [Документація PyTorch](https://pytorch.org/docs/stable/index.html)\n",
    "- [Документація scikit-learn](https://scikit-learn.org/stable/documentation.html)\n",
    "- [Kaggle Datasets](https://www.kaggle.com/datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NeqgMqm2UETO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data.drop(['Class'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled, data['Class'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_forest = IsolationForest(contamination=0.01)  \n",
    "iso_forest.fit(X_train)\n",
    "\n",
    "y_pred_iso = iso_forest.predict(X_test)\n",
    "y_pred_iso = [1 if i == 1 else 0 for i in y_pred_iso] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_class_svm = OneClassSVM(nu=0.01, kernel='rbf', gamma='scale')\n",
    "one_class_svm.fit(X_train)\n",
    "\n",
    "y_pred_svm = one_class_svm.predict(X_test)\n",
    "y_pred_svm = [1 if i == 1 else 0 for i in y_pred_svm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.01)\n",
    "y_pred_lof = lof.fit_predict(X_test)\n",
    "y_pred_lof = [1 if i == 1 else 0 for i in y_pred_lof]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(30, 15),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(15, 7)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(7, 15),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(15, 30)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "model = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    reconstructed = model(X_train_tensor)\n",
    "    loss = criterion(reconstructed, X_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "reconstructed_test = model(X_test_tensor)\n",
    "reconstruction_error = torch.mean((reconstructed_test - X_test_tensor)**2, dim=1).detach().numpy()\n",
    "\n",
    "threshold = 0.1 \n",
    "y_pred_ae = [1 if e > threshold else 0 for e in reconstruction_error]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Isolation Forest:\")\n",
    "print(classification_report(y_test, y_pred_iso))\n",
    "\n",
    "print(\"One-Class SVM:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "print(\"Local Outlier Factor:\")\n",
    "print(classification_report(y_test, y_pred_lof))\n",
    "\n",
    "print(\"Autoencoder:\")\n",
    "print(classification_report(y_test, y_pred_ae))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
